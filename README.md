# OvernightPredict

**Recursive Agent System with Self-Correction (ë©”íƒ€ì¸ì§€ ê¸°ë°˜ ììœ¨ ìˆ˜ì • ì‹œìŠ¤í…œ)**

An enterprise-grade system that implements meta-cognition capabilities to evaluate and adjust its own prediction strategies in real-time.

## Features

### Core Capabilities

- **OODA Loop Implementation**: Forecast â†’ Execute â†’ Evaluate â†’ Tune cycle running in parallel
- **Meta-Cognition**: Real-time self-evaluation and strategy adjustment
- **Multi-Provider Support**: OpenAI, DeepSeek, Claude/Anthropic
- **Parallel Sessions**: Run multiple sessions simultaneously with shared context
- **Clean Architecture**: Domain-driven design with clear boundaries
- **Strategy Pattern**: Dynamic algorithm replacement based on performance

### Architecture Components

| Component | Role | Description |
|-----------|------|-------------|
| **Orchestrator** | Coordinator | Manages multiple sessions in parallel |
| **Forecaster** | Prefrontal Cortex | Predicts future questions/tasks based on context |
| **Executor** | Worker | Executes tasks and generates code |
| **Evaluator** | Critic | Measures semantic similarity between predicted and actual questions |
| **MetaTuner** | Optimizer | Adjusts strategies when accuracy drops |

### Key Features

- ğŸ“Š **Prediction Accuracy Tracking**: Semantic similarity-based evaluation
- ğŸ”„ **Auto-Strategy Switching**: Automatically changes strategies when performance degrades
- ğŸŒ **Context Sharing**: Share progress across sessions (file, cloud, Redis)
- â±ï¸ **Rate Limit Handling**: Automatic wait and retry for Claude Code limits
- ğŸ“ˆ **Real-time Dashboard**: TUI dashboard for monitoring all sessions

## Installation

```bash
# Clone the repository
git clone https://github.com/your-org/overnightPredict.git
cd overnightPredict

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

## Configuration

Copy the example configuration and set your API keys:

```bash
cp config/.env.example .env
```

Edit `.env` with your credentials:

```env
# Required: At least one provider
OPENAI_API_KEY=sk-your-key-here
OPENAI_ENABLED=true

# Optional: Additional providers
CLAUDE_API_KEY=sk-ant-your-key-here
CLAUDE_ENABLED=true

DEEPSEEK_API_KEY=your-key-here
DEEPSEEK_ENABLED=false
```

## Usage

### Interactive CLI

```bash
python main.py
```

This starts the interactive CLI where you can:
1. Configure providers
2. Create sessions
3. Process questions
4. Monitor status
5. Launch the dashboard

### Quick Session Creation

```bash
# Create a session with OpenAI
python main.py --create openai --prompt "Build a REST API for user management"

# Create parallel sessions across providers
python main.py --parallel openai,claude --prompt "Implement a caching system"
```

### TUI Dashboard

```bash
python main.py --dashboard
```

Launch the real-time monitoring dashboard to:
- View all sessions status
- Start/stop sessions
- Send questions to sessions
- Monitor prediction accuracy

## Architecture

```
src/
â”œâ”€â”€ domain/                 # Enterprise business rules
â”‚   â”œâ”€â”€ entities/          # Session, Prediction, Question, Task
â”‚   â”œâ”€â”€ value_objects/     # AccuracyScore, Context
â”‚   â””â”€â”€ interfaces/        # Ports for infrastructure
â”‚
â”œâ”€â”€ application/           # Application business rules
â”‚   â”œâ”€â”€ services/          # Orchestrator, Forecaster, Executor, Evaluator, MetaTuner
â”‚   â”œâ”€â”€ use_cases/         # Application use cases
â”‚   â””â”€â”€ dto/               # Data transfer objects
â”‚
â”œâ”€â”€ infrastructure/        # External interfaces
â”‚   â”œâ”€â”€ llm_providers/     # OpenAI, DeepSeek, Claude implementations
â”‚   â”œâ”€â”€ storage/           # SQLite repository, Event bus
â”‚   â”œâ”€â”€ context_sharing/   # File, Cloud, Redis sharing
â”‚   â””â”€â”€ rate_limiting/     # Token bucket, Sliding window
â”‚
â””â”€â”€ presentation/          # UI Layer
    â”œâ”€â”€ cli/               # Command-line interface
    â”œâ”€â”€ dashboard/         # TUI dashboard (Textual)
    â””â”€â”€ controllers/       # Session controllers
```

## OODA Loop Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        OBSERVE                               â”‚
â”‚  - Receive actual question from user                        â”‚
â”‚  - Check pending predictions for matches                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ORIENT                                â”‚
â”‚  - Evaluate prediction accuracy (semantic similarity)        â”‚
â”‚  - Update context with new information                       â”‚
â”‚  - Track accuracy metrics                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DECIDE                                â”‚
â”‚  - Use predicted answer if accuracy >= threshold            â”‚
â”‚  - Or execute fresh with LLM                                â”‚
â”‚  - Determine if strategy change needed                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ACT                                  â”‚
â”‚  - Return answer to user                                    â”‚
â”‚  - Generate new predictions (lookahead)                     â”‚
â”‚  - Apply strategy adjustments if needed                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Context Sharing

Enable sessions to share context and progress:

```env
# File-based (same machine)
CONTEXT_ENABLED=true
CONTEXT_SHARING_TYPE=file
CONTEXT_SHARED_PATH=.overnight/shared

# Cloud-based (distributed)
CONTEXT_ENABLED=true
CONTEXT_SHARING_TYPE=cloud_bucket
CONTEXT_BUCKET_NAME=my-bucket
```

## Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test file
pytest tests/unit/test_entities.py -v
```

## API Reference

### SessionController

```python
from src.presentation.controllers import SessionController

controller = SessionController(orchestrator)

# Create session
session_id = await controller.create_session(
    provider="openai",
    name="My Session",
    initial_prompt="Build a web scraper",
)

# Process question
answer = await controller.ask(session_id, "How should I handle pagination?")

# Get status
status = controller.get_status(session_id)
print(f"Accuracy: {status['metrics']['prediction_accuracy']:.1%}")
```

### Orchestrator

```python
from src.application.services.orchestrator import Orchestrator

# Create parallel sessions
group_id = await orchestrator.create_session_group(
    providers=[LLMProvider.OPENAI, LLMProvider.CLAUDE],
    initial_prompt="Implement authentication system",
)

# Share context across group
await orchestrator.broadcast_context(
    group_id=group_id,
    content="User model: id, email, password_hash",
    context_type=ContextType.CODE,
)
```

## Configuration Reference

| Variable | Description | Default |
|----------|-------------|---------|
| `PREDICTION_ACCURACY_THRESHOLD` | Similarity threshold for matching | 0.7 |
| `PREDICTION_LOOKAHEAD_COUNT` | Questions to predict ahead | 5 |
| `PREDICTION_MIN_ACCURACY_FOR_KEEP` | Min accuracy before strategy switch | 0.6 |
| `ORCHESTRATOR_MAX_SESSIONS` | Maximum concurrent sessions | 10 |
| `ORCHESTRATOR_SESSION_TIMEOUT` | Session timeout in seconds | 3600 |

## License

MIT License - See LICENSE file for details.

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests: `pytest`
5. Submit a pull request
